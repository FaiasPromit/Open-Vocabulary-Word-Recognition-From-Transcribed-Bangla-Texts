{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Cite this paper if this code helps you:\n",
        "F. Satter and S. M. Masudul Ahsan, \"Open Vocabulary Word Recognition From Transcribed Bangla Texts,\" 2023 26th International Conference on Computer and Information Technology (ICCIT), Cox's Bazar, Bangladesh, 2023, pp. 1-6, doi: 10.1109/ICCIT60459.2023.10441393."
      ],
      "metadata": {
        "id": "KirEtb15XRDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutorial for Training: https://www.youtube.com/watch?v=amURyS6CAaY\n",
        "\n",
        "Everything is same except\n",
        "\n",
        "\n",
        "*   The third cell[models template]\n",
        "*   ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config file\n",
        "*   \"Creation of Label Map\" cell\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Necessary Dataset can be found here : https://data.mendeley.com/datasets/fnw59h7y89/2 in the \"PromitoLipi2.1\" folder"
      ],
      "metadata": {
        "id": "hCX4ETnIXTKO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYc03f2O6tZy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1fwWx8P80ug",
        "outputId": "841ad795-fe5c-4416-b7be-1888774e9422"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#mount drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# # this creates a symbolic link so that now the path /content/gdrive/My Drive/ is equal to /mydrive\n",
        "\n",
        "# !ln -s /content/gdrive/My Drive/ /mydrive\n",
        "# !ls /mydrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO3wNZph9KWU",
        "outputId": "8ad57e3b-2e50-4134-ed9d-17f57ce80040"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/models/research\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.45.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (8.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (4.9.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (3.5.3)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.29.33)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.0.6)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.11.3-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.31.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.11.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 KB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.22.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.70.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.3)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.7.0.72)\n",
            "Requirement already satisfied: tensorflow~=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.4/662.4 KB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting immutabledict\n",
            "  Downloading immutabledict-2.2.3-py3-none-any.whl (4.0 kB)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Collecting tensorflow-text~=2.11.0\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n",
            "Collecting fasteners<1.0,>=0.3\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (4.5.0)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.8.7-cp38-cp38-manylinux_2_28_x86_64.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.7/140.7 KB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<10.0.0,>=0.15.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Collecting objsize<0.7.0,>=0.6.1\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.22.2)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.51.3)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.7.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting zstandard<1,>=0.18.0\n",
            "  Downloading zstandard-0.20.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Requirement already satisfied: httplib2<0.21.0,>=0.8 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 KB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf<4,>3.12.2 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.19.6)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.2/526.2 KB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (23.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (4.38.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.31.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_io->object-detection==0.1) (0.31.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.16.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.12.7)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.26.14)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (4.0.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.11.2)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (23.1.21)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (15.0.6.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.12.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (8.1.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.38.4)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.15.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.58.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (6.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Building wheels for collected packages: object-detection, avro-python3, dill, seqeval, docopt\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696872 sha256=e8c45ecbec07a416161dd7b15fa9fbe25bc81657387e1e56417b085265145beb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jcnp3jlp/wheels/7d/96/c1/072a751379735e8dfdada1def1c62a89afb3cc45654fd6fd28\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44009 sha256=f496e919227425e1b9a6fdfb1195d957e1eb294575e76fe5eb698a6c50e8cbc8\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/73/e9/d273421f5723c4bf544dcf9eb097bda94421ef8d3252699f0a\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=6a615f0a59f393897c195d8c151c029d7727098f5a8385c42ec912881f9afe78\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/35/78/e9004fa30578734db7f10e7a211605f3f0778d2bdde38a239d\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=5ef88f9708d635acaf2e3dc12c04964fba22da7a0afbed31944eb0ea709a6630\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=831adce959322030be9581bcf953723e475d915853ac143da7f7a85161b544f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
            "Successfully built object-detection avro-python3 dill seqeval docopt\n",
            "Installing collected packages: sentencepiece, py-cpuinfo, docopt, zstandard, tf-slim, tensorflow-model-optimization, tensorflow_io, tensorflow-addons, pyyaml, pyparsing, pymongo, portalocker, orjson, objsize, immutabledict, fasteners, fastavro, dill, colorama, avro-python3, sacrebleu, hdfs, seqeval, lvis, apache-beam, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.3.3\n",
            "    Uninstalling pymongo-4.3.3:\n",
            "      Successfully uninstalled pymongo-4.3.3\n",
            "Successfully installed apache-beam-2.45.0 avro-python3-1.10.2 colorama-0.4.6 dill-0.3.1.1 docopt-0.6.2 fastavro-1.7.2 fasteners-0.18 hdfs-2.7.0 immutabledict-2.2.3 lvis-0.5.3 object-detection-0.1 objsize-0.6.1 orjson-3.8.7 portalocker-2.7.0 py-cpuinfo-9.0.0 pymongo-3.13.0 pyparsing-2.4.7 pyyaml-5.4.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorflow-addons-0.19.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.11.0 tensorflow_io-0.31.0 tf-models-official-2.11.3 tf-slim-1.1.0 zstandard-0.20.0\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/models (1)/research\n",
        "\n",
        "# Compile protos.\n",
        "\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# Install TensorFlow Object Detection API.\n",
        "\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install .\n",
        "#ekhane ekta . deya lagse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2rx1Aqv-CB2",
        "outputId": "2e4c91f8-bf14-41db-e984-2ffae73c73f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-03-04 22:21:21.060834: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-04 22:21:21.060931: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-04 22:21:21.060950: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Running tests under Python 3.8.10: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2023-03-04 22:21:27.995508: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0304 22:21:28.637244 139985009137472 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 4.29s\n",
            "I0304 22:21:29.695622 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 4.29s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 2.44s\n",
            "I0304 22:21:32.142149 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 2.44s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.93s\n",
            "I0304 22:21:33.068190 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.93s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.95s\n",
            "I0304 22:21:34.021868 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.95s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 4.53s\n",
            "I0304 22:21:38.551016 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 4.53s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0304 22:21:38.571634 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.43s\n",
            "I0304 22:21:39.004923 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.43s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0304 22:21:39.030378 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "I0304 22:21:39.056577 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.24s\n",
            "I0304 22:21:39.297988 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.24s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.15s\n",
            "I0304 22:21:39.447215 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.15s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.22s\n",
            "I0304 22:21:39.672245 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.22s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.15s\n",
            "I0304 22:21:39.821888 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.15s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.16s\n",
            "I0304 22:21:39.986435 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.16s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "I0304 22:21:40.031125 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0304 22:21:40.363011 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0304 22:21:40.363205 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 64\n",
            "I0304 22:21:40.363281 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 3\n",
            "I0304 22:21:40.367838 139985009137472 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0304 22:21:40.407256 139985009137472 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0304 22:21:40.407428 139985009137472 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0304 22:21:40.522746 139985009137472 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0304 22:21:40.522948 139985009137472 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0304 22:21:40.826450 139985009137472 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0304 22:21:40.826659 139985009137472 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0304 22:21:41.130838 139985009137472 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0304 22:21:41.131040 139985009137472 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0304 22:21:41.635167 139985009137472 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0304 22:21:41.635345 139985009137472 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0304 22:21:42.072705 139985009137472 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0304 22:21:42.072906 139985009137472 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0304 22:21:42.800866 139985009137472 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0304 22:21:42.801057 139985009137472 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0304 22:21:42.943264 139985009137472 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0304 22:21:43.035655 139985009137472 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0304 22:21:43.178176 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0304 22:21:43.178387 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n",
            "I0304 22:21:43.178499 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 4\n",
            "I0304 22:21:43.181344 139985009137472 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0304 22:21:43.208798 139985009137472 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0304 22:21:43.208947 139985009137472 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0304 22:21:43.446146 139985009137472 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0304 22:21:43.446360 139985009137472 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0304 22:21:43.910465 139985009137472 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0304 22:21:43.910695 139985009137472 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0304 22:21:44.478497 139985009137472 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0304 22:21:44.478718 139985009137472 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0304 22:21:45.700650 139985009137472 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0304 22:21:45.700858 139985009137472 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0304 22:21:47.188160 139985009137472 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0304 22:21:47.188344 139985009137472 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0304 22:21:48.866291 139985009137472 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0304 22:21:48.866490 139985009137472 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0304 22:21:49.941558 139985009137472 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0304 22:21:50.111411 139985009137472 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0304 22:21:50.337363 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0304 22:21:50.337713 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 112\n",
            "I0304 22:21:50.337814 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 5\n",
            "I0304 22:21:50.340865 139985009137472 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0304 22:21:50.370824 139985009137472 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0304 22:21:50.370956 139985009137472 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0304 22:21:50.816525 139985009137472 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0304 22:21:50.816725 139985009137472 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0304 22:21:51.692846 139985009137472 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0304 22:21:51.699664 139985009137472 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0304 22:21:52.835874 139985009137472 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0304 22:21:52.836087 139985009137472 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0304 22:21:54.222423 139985009137472 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0304 22:21:54.224675 139985009137472 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0304 22:21:55.540862 139985009137472 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0304 22:21:55.541640 139985009137472 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0304 22:21:56.079979 139985009137472 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0304 22:21:56.080132 139985009137472 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0304 22:21:56.278507 139985009137472 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0304 22:21:56.317454 139985009137472 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0304 22:21:56.372285 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0304 22:21:56.372417 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 160\n",
            "I0304 22:21:56.372483 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 6\n",
            "I0304 22:21:56.374384 139985009137472 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0304 22:21:56.395418 139985009137472 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0304 22:21:56.395521 139985009137472 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0304 22:21:56.531694 139985009137472 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0304 22:21:56.531826 139985009137472 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0304 22:21:56.779582 139985009137472 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0304 22:21:56.779723 139985009137472 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0304 22:21:57.028438 139985009137472 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0304 22:21:57.028599 139985009137472 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0304 22:21:57.445740 139985009137472 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0304 22:21:57.445902 139985009137472 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0304 22:21:57.857856 139985009137472 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0304 22:21:57.858011 139985009137472 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0304 22:21:58.367064 139985009137472 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0304 22:21:58.367220 139985009137472 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0304 22:21:58.546186 139985009137472 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0304 22:21:58.580369 139985009137472 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0304 22:21:58.640460 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0304 22:21:58.640603 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 224\n",
            "I0304 22:21:58.640669 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
            "I0304 22:21:58.642178 139985009137472 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0304 22:21:58.660327 139985009137472 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0304 22:21:58.660428 139985009137472 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0304 22:21:58.792737 139985009137472 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0304 22:21:58.792871 139985009137472 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0304 22:21:59.122869 139985009137472 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0304 22:21:59.123031 139985009137472 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0304 22:21:59.469122 139985009137472 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0304 22:21:59.469301 139985009137472 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0304 22:21:59.953144 139985009137472 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0304 22:21:59.953308 139985009137472 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0304 22:22:00.693397 139985009137472 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0304 22:22:00.693567 139985009137472 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0304 22:22:01.368391 139985009137472 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0304 22:22:01.368556 139985009137472 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0304 22:22:01.542668 139985009137472 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0304 22:22:01.577468 139985009137472 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0304 22:22:01.645953 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0304 22:22:01.646087 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 288\n",
            "I0304 22:22:01.646155 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
            "I0304 22:22:01.647667 139985009137472 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0304 22:22:01.663869 139985009137472 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0304 22:22:01.663994 139985009137472 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0304 22:22:01.853550 139985009137472 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0304 22:22:01.853684 139985009137472 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0304 22:22:02.271763 139985009137472 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0304 22:22:02.271919 139985009137472 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0304 22:22:02.690379 139985009137472 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0304 22:22:02.690617 139985009137472 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0304 22:22:03.282505 139985009137472 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0304 22:22:03.282694 139985009137472 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0304 22:22:03.868323 139985009137472 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0304 22:22:03.868485 139985009137472 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0304 22:22:04.616241 139985009137472 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0304 22:22:04.616403 139985009137472 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0304 22:22:04.870068 139985009137472 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0304 22:22:04.904556 139985009137472 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0304 22:22:04.982319 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0304 22:22:04.982457 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I0304 22:22:04.982525 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
            "I0304 22:22:04.984056 139985009137472 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0304 22:22:05.002773 139985009137472 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0304 22:22:05.002883 139985009137472 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0304 22:22:05.200134 139985009137472 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0304 22:22:05.200292 139985009137472 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0304 22:22:05.781299 139985009137472 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0304 22:22:05.781506 139985009137472 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0304 22:22:06.487912 139985009137472 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0304 22:22:06.488099 139985009137472 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0304 22:22:07.703596 139985009137472 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0304 22:22:07.703779 139985009137472 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0304 22:22:08.664408 139985009137472 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0304 22:22:08.664603 139985009137472 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0304 22:22:10.040874 139985009137472 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0304 22:22:10.041080 139985009137472 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0304 22:22:10.435311 139985009137472 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0304 22:22:10.485682 139985009137472 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0304 22:22:10.629446 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0304 22:22:10.629643 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I0304 22:22:10.629738 139985009137472 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
            "I0304 22:22:10.632166 139985009137472 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0304 22:22:10.659492 139985009137472 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0304 22:22:10.659644 139985009137472 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0304 22:22:11.078033 139985009137472 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0304 22:22:11.078230 139985009137472 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0304 22:22:11.933936 139985009137472 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0304 22:22:11.934125 139985009137472 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0304 22:22:12.803926 139985009137472 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0304 22:22:12.804118 139985009137472 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0304 22:22:13.880429 139985009137472 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0304 22:22:13.880599 139985009137472 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0304 22:22:14.705776 139985009137472 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0304 22:22:14.705935 139985009137472 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0304 22:22:15.778382 139985009137472 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0304 22:22:15.778576 139985009137472 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0304 22:22:16.131602 139985009137472 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0304 22:22:16.169583 139985009137472 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 36.48s\n",
            "I0304 22:22:16.513839 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 36.48s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0304 22:22:16.546384 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0304 22:22:16.548197 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0304 22:22:16.548765 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.03s\n",
            "I0304 22:22:16.576666 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.01s\n",
            "I0304 22:22:16.588430 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0304 22:22:16.588936 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0304 22:22:16.590283 139985009137472 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 51.182s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "!python object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "20NBRD4h-F9n",
        "outputId": "50089fbc-9088-47b4-eaba-9353088536ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/customTF2/data\n"
          ]
        }
      ],
      "source": [
        "cd /content/gdrive/MyDrive/customTF2/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6Av6qyPAC5y",
        "outputId": "4bc3dab2-b9e7-45dc-9259-e2c60b4d64c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully converted train_labels xml to csv.\n",
            "Successfully converted test_labels xml to csv.\n",
            "Successfully created label_map.pbtxt \n"
          ]
        }
      ],
      "source": [
        "#adjusted from: https://github.com/datitran/raccoon_dataset\n",
        "def xml_to_csv(path):\n",
        "  classes_names = []\n",
        "  xml_list = []\n",
        "\n",
        "  for xml_file in glob.glob(path + '/*.xml'):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    for member in root.findall('object'):\n",
        "      classes_names.append(member[0].text)\n",
        "      value = (root.find('filename').text  ,\n",
        "               int(root.find('size')[0].text),\n",
        "               int(root.find('size')[1].text),\n",
        "               member[0].text,\n",
        "               int(member[4][0].text),\n",
        "               int(member[4][1].text),\n",
        "               int(member[4][2].text),\n",
        "               int(member[4][3].text))\n",
        "      xml_list.append(value)\n",
        "  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "  xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "  classes_names = list(set(classes_names))\n",
        "  classes_names.sort()\n",
        "  return xml_df, classes_names\n",
        "\n",
        "for label_path in ['train_labels', 'test_labels']:\n",
        "  image_path = os.path.join(os.getcwd(), label_path)\n",
        "  xml_df, classes = xml_to_csv(label_path)\n",
        "  xml_df.to_csv(f'{label_path}.csv', index=None)\n",
        "  print(f'Successfully converted {label_path} xml to csv.')\n",
        "\n",
        "label_map_path = os.path.join(\"label_map.pbtxt\")\n",
        "pbtxt_content = \"\"\n",
        "\n",
        "for i, class_name in enumerate(classes):\n",
        "    pbtxt_content = (\n",
        "        pbtxt_content\n",
        "        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(i + 1, class_name)\n",
        "    )\n",
        "pbtxt_content = pbtxt_content.strip()\n",
        "with open(label_map_path, \"w\") as f:\n",
        "    f.write(pbtxt_content)\n",
        "    print('Successfully created label_map.pbtxt ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-KqmaoSAEdL"
      },
      "outputs": [],
      "source": [
        "labels = [{'id':'1', 'name':1},\n",
        "{'id':'2', 'name':2},\n",
        "{'id':'3', 'name':3},\n",
        "{'id':'4', 'name':4},\n",
        "{'id':'5', 'name':5},\n",
        "{'id':'6', 'name':6},\n",
        "{'id':'7', 'name':7},\n",
        "{'id':'8', 'name':8},\n",
        "{'id':'9', 'name':9},\n",
        "{'id':'10', 'name':10},\n",
        "{'id':'11', 'name':11},\n",
        "{'id':'12', 'name':12},\n",
        "{'id':'13', 'name':13},\n",
        "{'id':'14', 'name':14},\n",
        "{'id':'15', 'name':15},\n",
        "{'id':'16', 'name':16},\n",
        "{'id':'17', 'name':17},\n",
        "{'id':'18', 'name':18},\n",
        "{'id':'19', 'name':19},\n",
        "{'id':'20', 'name':20},\n",
        "{'id':'21', 'name':21},\n",
        "{'id':'22', 'name':22},\n",
        "{'id':'23', 'name':23},\n",
        "{'id':'24', 'name':24},\n",
        "{'id':'25', 'name':25},\n",
        "{'id':'26', 'name':26},\n",
        "{'id':'27', 'name':27},\n",
        "{'id':'28', 'name':28},\n",
        "{'id':'29', 'name':29},\n",
        "{'id':'30', 'name':30},\n",
        "{'id':'31', 'name':31},\n",
        "{'id':'32', 'name':32},\n",
        "{'id':'33', 'name':33},\n",
        "{'id':'34', 'name':34},\n",
        "{'id':'35', 'name':35},\n",
        "{'id':'36', 'name':36},\n",
        "{'id':'37', 'name':37},\n",
        "{'id':'38', 'name':38},\n",
        "{'id':'39', 'name':39},\n",
        "{'id':'40', 'name':40},\n",
        "{'id':'41', 'name':41},\n",
        "{'id':'42', 'name':42},\n",
        "{'id':'43', 'name':43},\n",
        "{'id':'44', 'name':44},\n",
        "{'id':'45', 'name':45},\n",
        "{'id':'46', 'name':46},\n",
        "{'id':'47', 'name':47},\n",
        "{'id':'48', 'name':48},\n",
        "{'id':'49', 'name':49},\n",
        "{'id':'50', 'name':50},\n",
        "{'id':'51', 'name':51},\n",
        "{'id':'52', 'name':52},\n",
        "{'id':'53', 'name':53},\n",
        "{'id':'54', 'name':54},\n",
        "{'id':'55', 'name':55},\n",
        "{'id':'56', 'name':56},\n",
        "{'id':'57', 'name':57},\n",
        "{'id':'58', 'name':58},\n",
        "{'id':'59', 'name':59},\n",
        "{'id':'60', 'name':60},\n",
        "{'id':'61', 'name':61},\n",
        "{'id':'62', 'name':62},\n",
        "{'id':'63', 'name':63},\n",
        "{'id':'64', 'name':64},\n",
        "{'id':'65', 'name':65},\n",
        "{'id':'66', 'name':66},\n",
        "{'id':'67', 'name':67},\n",
        "{'id':'68', 'name':68},\n",
        "{'id':'69', 'name':69},\n",
        "{'id':'70', 'name':70},\n",
        "{'id':'71', 'name':71},\n",
        "{'id':'72', 'name':72},\n",
        "{'id':'73', 'name':73},\n",
        "{'id':'74', 'name':74},\n",
        "{'id':'75', 'name':75},\n",
        "{'id':'76', 'name':76},\n",
        "{'id':'77', 'name':77},\n",
        "{'id':'78', 'name':78},\n",
        "{'id':'79', 'name':79},\n",
        "{'id':'80', 'name':80},\n",
        "{'id':'81', 'name':81},\n",
        "{'id':'82', 'name':82},\n",
        "{'id':'83', 'name':83},\n",
        "{'id':'84', 'name':84},\n",
        "{'id':'85', 'name':85},\n",
        "{'id':'86', 'name':86},\n",
        "{'id':'87', 'name':87},\n",
        "{'id':'88', 'name':88},\n",
        "{'id':'89', 'name':89},\n",
        "{'id':'90', 'name':90},\n",
        "{'id':'91', 'name':91},\n",
        "{'id':'92', 'name':92},]\n",
        "\n",
        "with open('/content/gdrive/MyDrive/customTF2/data/label_map.pbtxt', 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLKnQzjOAGJT",
        "outputId": "7ee45f43-4123-4986-e2b7-cd2cf33a1237"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-03-01 15:32:01.635278: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-01 15:32:01.641189: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-01 15:32:01.641222: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "groups: 100% 442/442 [04:57<00:00,  1.49it/s]\n",
            "Successfully created the TFRecords: /content/gdrive/MyDrive/customTF2/data/test.record\n"
          ]
        }
      ],
      "source": [
        "#Usage:\n",
        "#!python generate_tfrecord.py output.csv output_pb.txt /path/to/images output.tfrecords\n",
        "\n",
        "#For train.record\n",
        "# !python /content/gdrive/MyDrive/customTF2/generate_tfrecord.py train_labels.csv  label_map.pbtxt images/ train.record\n",
        "\n",
        "#For test.record\n",
        "!python /content/gdrive/MyDrive/customTF2/generate_tfrecord.py test_labels.csv  label_map.pbtxt images/ test.record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE-z3T4wAgik",
        "outputId": "49105fd5-e461-48de-b5e9-fe62db690d3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n"
          ]
        }
      ],
      "source": [
        "%cd /content/models/research/object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8IxqQqCAiHa",
        "outputId": "cdcfeeef-71d0-4492-cda7-e8bb478356fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-03-01 14:56:06.677699: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-01 14:56:06.677816: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-01 14:56:06.677840: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-01 14:56:12.092957: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0301 14:56:12.121229 140010801207104 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0301 14:56:13.322992 140010801207104 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0301 14:56:13.323203 140010801207104 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0301 14:56:13.350987 140010801207104 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/gdrive/MyDrive/customTF2/data/train.record']\n",
            "I0301 14:56:14.499402 140010801207104 dataset_builder.py:162] Reading unweighted datasets: ['/content/gdrive/MyDrive/customTF2/data/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/gdrive/MyDrive/customTF2/data/train.record']\n",
            "I0301 14:56:14.500035 140010801207104 dataset_builder.py:79] Reading record datasets for input file: ['/content/gdrive/MyDrive/customTF2/data/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0301 14:56:14.500189 140010801207104 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0301 14:56:14.500262 140010801207104 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0301 14:56:14.508886 140010801207104 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0301 14:56:14.527173 140010801207104 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "W0301 14:56:15.088108 140010801207104 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0301 14:56:25.146735 140010801207104 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0301 14:56:32.955578 140010801207104 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0301 14:56:35.811436 140010801207104 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.8/dist-packages/keras/backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0301 14:57:29.199053 140005934610176 deprecation.py:554] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 42100 per-step time 0.750s\n",
            "I0301 14:58:43.894608 140010801207104 model_lib_v2.py:705] Step 42100 per-step time 0.750s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07016834,\n",
            " 'Loss/localization_loss': 0.024280533,\n",
            " 'Loss/regularization_loss': 0.08199599,\n",
            " 'Loss/total_loss': 0.17644486,\n",
            " 'learning_rate': 0.00502212}\n",
            "I0301 14:58:43.894964 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.07016834,\n",
            " 'Loss/localization_loss': 0.024280533,\n",
            " 'Loss/regularization_loss': 0.08199599,\n",
            " 'Loss/total_loss': 0.17644486,\n",
            " 'learning_rate': 0.00502212}\n",
            "INFO:tensorflow:Step 42200 per-step time 0.238s\n",
            "I0301 14:59:07.706722 140010801207104 model_lib_v2.py:705] Step 42200 per-step time 0.238s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0658827,\n",
            " 'Loss/localization_loss': 0.018328564,\n",
            " 'Loss/regularization_loss': 0.08196541,\n",
            " 'Loss/total_loss': 0.16617668,\n",
            " 'learning_rate': 0.004898429}\n",
            "I0301 14:59:07.707087 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.0658827,\n",
            " 'Loss/localization_loss': 0.018328564,\n",
            " 'Loss/regularization_loss': 0.08196541,\n",
            " 'Loss/total_loss': 0.16617668,\n",
            " 'learning_rate': 0.004898429}\n",
            "INFO:tensorflow:Step 42300 per-step time 0.236s\n",
            "I0301 14:59:31.342456 140010801207104 model_lib_v2.py:705] Step 42300 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07445606,\n",
            " 'Loss/localization_loss': 0.03023692,\n",
            " 'Loss/regularization_loss': 0.08193546,\n",
            " 'Loss/total_loss': 0.18662843,\n",
            " 'learning_rate': 0.004776175}\n",
            "I0301 14:59:31.342801 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.07445606,\n",
            " 'Loss/localization_loss': 0.03023692,\n",
            " 'Loss/regularization_loss': 0.08193546,\n",
            " 'Loss/total_loss': 0.18662843,\n",
            " 'learning_rate': 0.004776175}\n",
            "INFO:tensorflow:Step 42400 per-step time 0.236s\n",
            "I0301 14:59:54.924658 140010801207104 model_lib_v2.py:705] Step 42400 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06756132,\n",
            " 'Loss/localization_loss': 0.029434886,\n",
            " 'Loss/regularization_loss': 0.08190616,\n",
            " 'Loss/total_loss': 0.17890236,\n",
            " 'learning_rate': 0.004655375}\n",
            "I0301 14:59:54.924940 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.06756132,\n",
            " 'Loss/localization_loss': 0.029434886,\n",
            " 'Loss/regularization_loss': 0.08190616,\n",
            " 'Loss/total_loss': 0.17890236,\n",
            " 'learning_rate': 0.004655375}\n",
            "INFO:tensorflow:Step 42500 per-step time 0.238s\n",
            "I0301 15:00:18.759739 140010801207104 model_lib_v2.py:705] Step 42500 per-step time 0.238s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.053305253,\n",
            " 'Loss/localization_loss': 0.029381195,\n",
            " 'Loss/regularization_loss': 0.081877545,\n",
            " 'Loss/total_loss': 0.16456398,\n",
            " 'learning_rate': 0.004536023}\n",
            "I0301 15:00:18.760054 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.053305253,\n",
            " 'Loss/localization_loss': 0.029381195,\n",
            " 'Loss/regularization_loss': 0.081877545,\n",
            " 'Loss/total_loss': 0.16456398,\n",
            " 'learning_rate': 0.004536023}\n",
            "INFO:tensorflow:Step 42600 per-step time 0.237s\n",
            "I0301 15:00:42.461363 140010801207104 model_lib_v2.py:705] Step 42600 per-step time 0.237s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07416956,\n",
            " 'Loss/localization_loss': 0.033654343,\n",
            " 'Loss/regularization_loss': 0.081849605,\n",
            " 'Loss/total_loss': 0.18967351,\n",
            " 'learning_rate': 0.0044181347}\n",
            "I0301 15:00:42.461779 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.07416956,\n",
            " 'Loss/localization_loss': 0.033654343,\n",
            " 'Loss/regularization_loss': 0.081849605,\n",
            " 'Loss/total_loss': 0.18967351,\n",
            " 'learning_rate': 0.0044181347}\n",
            "INFO:tensorflow:Step 42700 per-step time 0.236s\n",
            "I0301 15:01:06.082739 140010801207104 model_lib_v2.py:705] Step 42700 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.079886734,\n",
            " 'Loss/localization_loss': 0.040173758,\n",
            " 'Loss/regularization_loss': 0.081822395,\n",
            " 'Loss/total_loss': 0.20188288,\n",
            " 'learning_rate': 0.0043017077}\n",
            "I0301 15:01:06.083082 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.079886734,\n",
            " 'Loss/localization_loss': 0.040173758,\n",
            " 'Loss/regularization_loss': 0.081822395,\n",
            " 'Loss/total_loss': 0.20188288,\n",
            " 'learning_rate': 0.0043017077}\n",
            "INFO:tensorflow:Step 42800 per-step time 0.237s\n",
            "I0301 15:01:29.779460 140010801207104 model_lib_v2.py:705] Step 42800 per-step time 0.237s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07253772,\n",
            " 'Loss/localization_loss': 0.02546452,\n",
            " 'Loss/regularization_loss': 0.08179603,\n",
            " 'Loss/total_loss': 0.17979828,\n",
            " 'learning_rate': 0.004186745}\n",
            "I0301 15:01:29.779754 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.07253772,\n",
            " 'Loss/localization_loss': 0.02546452,\n",
            " 'Loss/regularization_loss': 0.08179603,\n",
            " 'Loss/total_loss': 0.17979828,\n",
            " 'learning_rate': 0.004186745}\n",
            "INFO:tensorflow:Step 42900 per-step time 0.235s\n",
            "I0301 15:01:53.299937 140010801207104 model_lib_v2.py:705] Step 42900 per-step time 0.235s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.075502604,\n",
            " 'Loss/localization_loss': 0.024201365,\n",
            " 'Loss/regularization_loss': 0.08177018,\n",
            " 'Loss/total_loss': 0.18147415,\n",
            " 'learning_rate': 0.0040732576}\n",
            "I0301 15:01:53.300221 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.075502604,\n",
            " 'Loss/localization_loss': 0.024201365,\n",
            " 'Loss/regularization_loss': 0.08177018,\n",
            " 'Loss/total_loss': 0.18147415,\n",
            " 'learning_rate': 0.0040732576}\n",
            "INFO:tensorflow:Step 43000 per-step time 0.238s\n",
            "I0301 15:02:17.074944 140010801207104 model_lib_v2.py:705] Step 43000 per-step time 0.238s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06846685,\n",
            " 'Loss/localization_loss': 0.027209036,\n",
            " 'Loss/regularization_loss': 0.08174513,\n",
            " 'Loss/total_loss': 0.17742102,\n",
            " 'learning_rate': 0.003961246}\n",
            "I0301 15:02:17.075247 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.06846685,\n",
            " 'Loss/localization_loss': 0.027209036,\n",
            " 'Loss/regularization_loss': 0.08174513,\n",
            " 'Loss/total_loss': 0.17742102,\n",
            " 'learning_rate': 0.003961246}\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0301 15:02:17.167616 140010801207104 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0301 15:02:17.169857 140010801207104 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0301 15:02:17.170960 140010801207104 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0301 15:02:17.171912 140010801207104 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0301 15:02:17.175406 140010801207104 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0301 15:02:17.176372 140010801207104 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0301 15:02:17.177371 140010801207104 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0301 15:02:17.178378 140010801207104 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0301 15:02:17.183035 140010801207104 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0301 15:02:17.184009 140010801207104 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Step 43100 per-step time 0.255s\n",
            "I0301 15:02:42.531446 140010801207104 model_lib_v2.py:705] Step 43100 per-step time 0.255s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.068437666,\n",
            " 'Loss/localization_loss': 0.028595498,\n",
            " 'Loss/regularization_loss': 0.081720695,\n",
            " 'Loss/total_loss': 0.17875385,\n",
            " 'learning_rate': 0.0038507176}\n",
            "I0301 15:02:42.531998 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.068437666,\n",
            " 'Loss/localization_loss': 0.028595498,\n",
            " 'Loss/regularization_loss': 0.081720695,\n",
            " 'Loss/total_loss': 0.17875385,\n",
            " 'learning_rate': 0.0038507176}\n",
            "INFO:tensorflow:Step 43200 per-step time 0.237s\n",
            "I0301 15:03:06.235993 140010801207104 model_lib_v2.py:705] Step 43200 per-step time 0.237s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.058973752,\n",
            " 'Loss/localization_loss': 0.02123044,\n",
            " 'Loss/regularization_loss': 0.08169699,\n",
            " 'Loss/total_loss': 0.16190118,\n",
            " 'learning_rate': 0.0037416671}\n",
            "I0301 15:03:06.236268 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.058973752,\n",
            " 'Loss/localization_loss': 0.02123044,\n",
            " 'Loss/regularization_loss': 0.08169699,\n",
            " 'Loss/total_loss': 0.16190118,\n",
            " 'learning_rate': 0.0037416671}\n",
            "INFO:tensorflow:Step 43300 per-step time 0.235s\n",
            "I0301 15:03:29.766540 140010801207104 model_lib_v2.py:705] Step 43300 per-step time 0.235s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.074212804,\n",
            " 'Loss/localization_loss': 0.025072932,\n",
            " 'Loss/regularization_loss': 0.08167385,\n",
            " 'Loss/total_loss': 0.18095958,\n",
            " 'learning_rate': 0.0036341143}\n",
            "I0301 15:03:29.766834 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.074212804,\n",
            " 'Loss/localization_loss': 0.025072932,\n",
            " 'Loss/regularization_loss': 0.08167385,\n",
            " 'Loss/total_loss': 0.18095958,\n",
            " 'learning_rate': 0.0036341143}\n",
            "INFO:tensorflow:Step 43400 per-step time 0.236s\n",
            "I0301 15:03:53.332321 140010801207104 model_lib_v2.py:705] Step 43400 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.076428555,\n",
            " 'Loss/localization_loss': 0.020209325,\n",
            " 'Loss/regularization_loss': 0.08165141,\n",
            " 'Loss/total_loss': 0.1782893,\n",
            " 'learning_rate': 0.003528056}\n",
            "I0301 15:03:53.332698 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.076428555,\n",
            " 'Loss/localization_loss': 0.020209325,\n",
            " 'Loss/regularization_loss': 0.08165141,\n",
            " 'Loss/total_loss': 0.1782893,\n",
            " 'learning_rate': 0.003528056}\n",
            "INFO:tensorflow:Step 43500 per-step time 0.236s\n",
            "I0301 15:04:16.936521 140010801207104 model_lib_v2.py:705] Step 43500 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06673344,\n",
            " 'Loss/localization_loss': 0.026946263,\n",
            " 'Loss/regularization_loss': 0.081629544,\n",
            " 'Loss/total_loss': 0.17530924,\n",
            " 'learning_rate': 0.0034234975}\n",
            "I0301 15:04:16.936890 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.06673344,\n",
            " 'Loss/localization_loss': 0.026946263,\n",
            " 'Loss/regularization_loss': 0.081629544,\n",
            " 'Loss/total_loss': 0.17530924,\n",
            " 'learning_rate': 0.0034234975}\n",
            "INFO:tensorflow:Step 43600 per-step time 0.237s\n",
            "I0301 15:04:40.601165 140010801207104 model_lib_v2.py:705] Step 43600 per-step time 0.237s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.066862136,\n",
            " 'Loss/localization_loss': 0.027409637,\n",
            " 'Loss/regularization_loss': 0.081608325,\n",
            " 'Loss/total_loss': 0.1758801,\n",
            " 'learning_rate': 0.0033204365}\n",
            "I0301 15:04:40.601463 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.066862136,\n",
            " 'Loss/localization_loss': 0.027409637,\n",
            " 'Loss/regularization_loss': 0.081608325,\n",
            " 'Loss/total_loss': 0.1758801,\n",
            " 'learning_rate': 0.0033204365}\n",
            "INFO:tensorflow:Step 43700 per-step time 0.236s\n",
            "I0301 15:05:04.240136 140010801207104 model_lib_v2.py:705] Step 43700 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.058195103,\n",
            " 'Loss/localization_loss': 0.03375971,\n",
            " 'Loss/regularization_loss': 0.08158764,\n",
            " 'Loss/total_loss': 0.17354245,\n",
            " 'learning_rate': 0.0032188867}\n",
            "I0301 15:05:04.240418 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.058195103,\n",
            " 'Loss/localization_loss': 0.03375971,\n",
            " 'Loss/regularization_loss': 0.08158764,\n",
            " 'Loss/total_loss': 0.17354245,\n",
            " 'learning_rate': 0.0032188867}\n",
            "INFO:tensorflow:Step 43800 per-step time 0.236s\n",
            "I0301 15:05:27.865517 140010801207104 model_lib_v2.py:705] Step 43800 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07924476,\n",
            " 'Loss/localization_loss': 0.019453313,\n",
            " 'Loss/regularization_loss': 0.08156766,\n",
            " 'Loss/total_loss': 0.18026574,\n",
            " 'learning_rate': 0.0031188512}\n",
            "I0301 15:05:27.865880 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.07924476,\n",
            " 'Loss/localization_loss': 0.019453313,\n",
            " 'Loss/regularization_loss': 0.08156766,\n",
            " 'Loss/total_loss': 0.18026574,\n",
            " 'learning_rate': 0.0031188512}\n",
            "INFO:tensorflow:Step 43900 per-step time 0.236s\n",
            "I0301 15:05:51.506106 140010801207104 model_lib_v2.py:705] Step 43900 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0575553,\n",
            " 'Loss/localization_loss': 0.023403998,\n",
            " 'Loss/regularization_loss': 0.08154829,\n",
            " 'Loss/total_loss': 0.1625076,\n",
            " 'learning_rate': 0.0030203317}\n",
            "I0301 15:05:51.506391 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.0575553,\n",
            " 'Loss/localization_loss': 0.023403998,\n",
            " 'Loss/regularization_loss': 0.08154829,\n",
            " 'Loss/total_loss': 0.1625076,\n",
            " 'learning_rate': 0.0030203317}\n",
            "INFO:tensorflow:Step 44000 per-step time 0.236s\n",
            "I0301 15:06:15.108626 140010801207104 model_lib_v2.py:705] Step 44000 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05972627,\n",
            " 'Loss/localization_loss': 0.020288559,\n",
            " 'Loss/regularization_loss': 0.08152949,\n",
            " 'Loss/total_loss': 0.16154432,\n",
            " 'learning_rate': 0.002923329}\n",
            "I0301 15:06:15.108919 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.05972627,\n",
            " 'Loss/localization_loss': 0.020288559,\n",
            " 'Loss/regularization_loss': 0.08152949,\n",
            " 'Loss/total_loss': 0.16154432,\n",
            " 'learning_rate': 0.002923329}\n",
            "INFO:tensorflow:Step 44100 per-step time 0.249s\n",
            "I0301 15:06:40.013932 140010801207104 model_lib_v2.py:705] Step 44100 per-step time 0.249s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.064075746,\n",
            " 'Loss/localization_loss': 0.018766763,\n",
            " 'Loss/regularization_loss': 0.08151128,\n",
            " 'Loss/total_loss': 0.16435379,\n",
            " 'learning_rate': 0.0028278518}\n",
            "I0301 15:06:40.014286 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.064075746,\n",
            " 'Loss/localization_loss': 0.018766763,\n",
            " 'Loss/regularization_loss': 0.08151128,\n",
            " 'Loss/total_loss': 0.16435379,\n",
            " 'learning_rate': 0.0028278518}\n",
            "INFO:tensorflow:Step 44200 per-step time 0.237s\n",
            "I0301 15:07:03.701211 140010801207104 model_lib_v2.py:705] Step 44200 per-step time 0.237s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07687295,\n",
            " 'Loss/localization_loss': 0.03173501,\n",
            " 'Loss/regularization_loss': 0.08149376,\n",
            " 'Loss/total_loss': 0.19010171,\n",
            " 'learning_rate': 0.0027339004}\n",
            "I0301 15:07:03.701622 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.07687295,\n",
            " 'Loss/localization_loss': 0.03173501,\n",
            " 'Loss/regularization_loss': 0.08149376,\n",
            " 'Loss/total_loss': 0.19010171,\n",
            " 'learning_rate': 0.0027339004}\n",
            "INFO:tensorflow:Step 44300 per-step time 0.237s\n",
            "I0301 15:07:27.436825 140010801207104 model_lib_v2.py:705] Step 44300 per-step time 0.237s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05805487,\n",
            " 'Loss/localization_loss': 0.021373343,\n",
            " 'Loss/regularization_loss': 0.08147671,\n",
            " 'Loss/total_loss': 0.16090491,\n",
            " 'learning_rate': 0.0026414846}\n",
            "I0301 15:07:27.437175 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.05805487,\n",
            " 'Loss/localization_loss': 0.021373343,\n",
            " 'Loss/regularization_loss': 0.08147671,\n",
            " 'Loss/total_loss': 0.16090491,\n",
            " 'learning_rate': 0.0026414846}\n",
            "INFO:tensorflow:Step 44400 per-step time 0.236s\n",
            "I0301 15:07:51.074499 140010801207104 model_lib_v2.py:705] Step 44400 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05785684,\n",
            " 'Loss/localization_loss': 0.02181698,\n",
            " 'Loss/regularization_loss': 0.0814602,\n",
            " 'Loss/total_loss': 0.16113402,\n",
            " 'learning_rate': 0.002550602}\n",
            "I0301 15:07:51.074806 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.05785684,\n",
            " 'Loss/localization_loss': 0.02181698,\n",
            " 'Loss/regularization_loss': 0.0814602,\n",
            " 'Loss/total_loss': 0.16113402,\n",
            " 'learning_rate': 0.002550602}\n",
            "INFO:tensorflow:Step 44500 per-step time 0.235s\n",
            "I0301 15:08:14.623159 140010801207104 model_lib_v2.py:705] Step 44500 per-step time 0.235s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06264285,\n",
            " 'Loss/localization_loss': 0.022676926,\n",
            " 'Loss/regularization_loss': 0.08144424,\n",
            " 'Loss/total_loss': 0.16676402,\n",
            " 'learning_rate': 0.0024612616}\n",
            "I0301 15:08:14.623450 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.06264285,\n",
            " 'Loss/localization_loss': 0.022676926,\n",
            " 'Loss/regularization_loss': 0.08144424,\n",
            " 'Loss/total_loss': 0.16676402,\n",
            " 'learning_rate': 0.0024612616}\n",
            "INFO:tensorflow:Step 44600 per-step time 0.236s\n",
            "I0301 15:08:38.204395 140010801207104 model_lib_v2.py:705] Step 44600 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0626905,\n",
            " 'Loss/localization_loss': 0.025082214,\n",
            " 'Loss/regularization_loss': 0.08142883,\n",
            " 'Loss/total_loss': 0.16920155,\n",
            " 'learning_rate': 0.002373464}\n",
            "I0301 15:08:38.204791 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.0626905,\n",
            " 'Loss/localization_loss': 0.025082214,\n",
            " 'Loss/regularization_loss': 0.08142883,\n",
            " 'Loss/total_loss': 0.16920155,\n",
            " 'learning_rate': 0.002373464}\n",
            "INFO:tensorflow:Step 44700 per-step time 0.236s\n",
            "I0301 15:09:01.815147 140010801207104 model_lib_v2.py:705] Step 44700 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.061767664,\n",
            " 'Loss/localization_loss': 0.018304944,\n",
            " 'Loss/regularization_loss': 0.081413954,\n",
            " 'Loss/total_loss': 0.16148657,\n",
            " 'learning_rate': 0.002287209}\n",
            "I0301 15:09:01.815442 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.061767664,\n",
            " 'Loss/localization_loss': 0.018304944,\n",
            " 'Loss/regularization_loss': 0.081413954,\n",
            " 'Loss/total_loss': 0.16148657,\n",
            " 'learning_rate': 0.002287209}\n",
            "INFO:tensorflow:Step 44800 per-step time 0.236s\n",
            "I0301 15:09:25.384671 140010801207104 model_lib_v2.py:705] Step 44800 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08607373,\n",
            " 'Loss/localization_loss': 0.036769144,\n",
            " 'Loss/regularization_loss': 0.08139967,\n",
            " 'Loss/total_loss': 0.20424254,\n",
            " 'learning_rate': 0.002202506}\n",
            "I0301 15:09:25.384955 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.08607373,\n",
            " 'Loss/localization_loss': 0.036769144,\n",
            " 'Loss/regularization_loss': 0.08139967,\n",
            " 'Loss/total_loss': 0.20424254,\n",
            " 'learning_rate': 0.002202506}\n",
            "INFO:tensorflow:Step 44900 per-step time 0.236s\n",
            "I0301 15:09:49.012296 140010801207104 model_lib_v2.py:705] Step 44900 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0743433,\n",
            " 'Loss/localization_loss': 0.01700844,\n",
            " 'Loss/regularization_loss': 0.08138586,\n",
            " 'Loss/total_loss': 0.1727376,\n",
            " 'learning_rate': 0.00211936}\n",
            "I0301 15:09:49.012656 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.0743433,\n",
            " 'Loss/localization_loss': 0.01700844,\n",
            " 'Loss/regularization_loss': 0.08138586,\n",
            " 'Loss/total_loss': 0.1727376,\n",
            " 'learning_rate': 0.00211936}\n",
            "INFO:tensorflow:Step 45000 per-step time 0.238s\n",
            "I0301 15:10:12.831760 140010801207104 model_lib_v2.py:705] Step 45000 per-step time 0.238s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.064055815,\n",
            " 'Loss/localization_loss': 0.032297015,\n",
            " 'Loss/regularization_loss': 0.081372656,\n",
            " 'Loss/total_loss': 0.1777255,\n",
            " 'learning_rate': 0.0020377683}\n",
            "I0301 15:10:12.832150 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.064055815,\n",
            " 'Loss/localization_loss': 0.032297015,\n",
            " 'Loss/regularization_loss': 0.081372656,\n",
            " 'Loss/total_loss': 0.1777255,\n",
            " 'learning_rate': 0.0020377683}\n",
            "INFO:tensorflow:Step 45100 per-step time 0.256s\n",
            "I0301 15:10:38.405368 140010801207104 model_lib_v2.py:705] Step 45100 per-step time 0.256s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.060873143,\n",
            " 'Loss/localization_loss': 0.017126784,\n",
            " 'Loss/regularization_loss': 0.08135994,\n",
            " 'Loss/total_loss': 0.15935987,\n",
            " 'learning_rate': 0.0019577406}\n",
            "I0301 15:10:38.405772 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.060873143,\n",
            " 'Loss/localization_loss': 0.017126784,\n",
            " 'Loss/regularization_loss': 0.08135994,\n",
            " 'Loss/total_loss': 0.15935987,\n",
            " 'learning_rate': 0.0019577406}\n",
            "INFO:tensorflow:Step 45200 per-step time 0.237s\n",
            "I0301 15:11:02.080883 140010801207104 model_lib_v2.py:705] Step 45200 per-step time 0.237s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05195539,\n",
            " 'Loss/localization_loss': 0.01787855,\n",
            " 'Loss/regularization_loss': 0.081347704,\n",
            " 'Loss/total_loss': 0.15118164,\n",
            " 'learning_rate': 0.0018792676}\n",
            "I0301 15:11:02.081200 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.05195539,\n",
            " 'Loss/localization_loss': 0.01787855,\n",
            " 'Loss/regularization_loss': 0.081347704,\n",
            " 'Loss/total_loss': 0.15118164,\n",
            " 'learning_rate': 0.0018792676}\n",
            "INFO:tensorflow:Step 45300 per-step time 0.236s\n",
            "I0301 15:11:25.730063 140010801207104 model_lib_v2.py:705] Step 45300 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06263584,\n",
            " 'Loss/localization_loss': 0.02445701,\n",
            " 'Loss/regularization_loss': 0.08133595,\n",
            " 'Loss/total_loss': 0.1684288,\n",
            " 'learning_rate': 0.0018023705}\n",
            "I0301 15:11:25.730397 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.06263584,\n",
            " 'Loss/localization_loss': 0.02445701,\n",
            " 'Loss/regularization_loss': 0.08133595,\n",
            " 'Loss/total_loss': 0.1684288,\n",
            " 'learning_rate': 0.0018023705}\n",
            "INFO:tensorflow:Step 45400 per-step time 0.237s\n",
            "I0301 15:11:49.416463 140010801207104 model_lib_v2.py:705] Step 45400 per-step time 0.237s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.065638445,\n",
            " 'Loss/localization_loss': 0.022549232,\n",
            " 'Loss/regularization_loss': 0.08132474,\n",
            " 'Loss/total_loss': 0.16951242,\n",
            " 'learning_rate': 0.0017270398}\n",
            "I0301 15:11:49.416837 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.065638445,\n",
            " 'Loss/localization_loss': 0.022549232,\n",
            " 'Loss/regularization_loss': 0.08132474,\n",
            " 'Loss/total_loss': 0.16951242,\n",
            " 'learning_rate': 0.0017270398}\n",
            "INFO:tensorflow:Step 45500 per-step time 0.237s\n",
            "I0301 15:12:13.096042 140010801207104 model_lib_v2.py:705] Step 45500 per-step time 0.237s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.061681762,\n",
            " 'Loss/localization_loss': 0.02696288,\n",
            " 'Loss/regularization_loss': 0.08131391,\n",
            " 'Loss/total_loss': 0.16995855,\n",
            " 'learning_rate': 0.001653285}\n",
            "I0301 15:12:13.096344 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.061681762,\n",
            " 'Loss/localization_loss': 0.02696288,\n",
            " 'Loss/regularization_loss': 0.08131391,\n",
            " 'Loss/total_loss': 0.16995855,\n",
            " 'learning_rate': 0.001653285}\n",
            "INFO:tensorflow:Step 45600 per-step time 0.235s\n",
            "I0301 15:12:36.576311 140010801207104 model_lib_v2.py:705] Step 45600 per-step time 0.235s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.059243295,\n",
            " 'Loss/localization_loss': 0.02076054,\n",
            " 'Loss/regularization_loss': 0.08130352,\n",
            " 'Loss/total_loss': 0.16130736,\n",
            " 'learning_rate': 0.0015811061}\n",
            "I0301 15:12:36.576621 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.059243295,\n",
            " 'Loss/localization_loss': 0.02076054,\n",
            " 'Loss/regularization_loss': 0.08130352,\n",
            " 'Loss/total_loss': 0.16130736,\n",
            " 'learning_rate': 0.0015811061}\n",
            "INFO:tensorflow:Step 45700 per-step time 0.235s\n",
            "I0301 15:13:00.122509 140010801207104 model_lib_v2.py:705] Step 45700 per-step time 0.235s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05871392,\n",
            " 'Loss/localization_loss': 0.026779847,\n",
            " 'Loss/regularization_loss': 0.08129357,\n",
            " 'Loss/total_loss': 0.16678733,\n",
            " 'learning_rate': 0.0015105009}\n",
            "I0301 15:13:00.122850 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.05871392,\n",
            " 'Loss/localization_loss': 0.026779847,\n",
            " 'Loss/regularization_loss': 0.08129357,\n",
            " 'Loss/total_loss': 0.16678733,\n",
            " 'learning_rate': 0.0015105009}\n",
            "INFO:tensorflow:Step 45800 per-step time 0.236s\n",
            "I0301 15:13:23.741289 140010801207104 model_lib_v2.py:705] Step 45800 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07245962,\n",
            " 'Loss/localization_loss': 0.020593483,\n",
            " 'Loss/regularization_loss': 0.08128405,\n",
            " 'Loss/total_loss': 0.17433715,\n",
            " 'learning_rate': 0.0014414835}\n",
            "I0301 15:13:23.741565 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.07245962,\n",
            " 'Loss/localization_loss': 0.020593483,\n",
            " 'Loss/regularization_loss': 0.08128405,\n",
            " 'Loss/total_loss': 0.17433715,\n",
            " 'learning_rate': 0.0014414835}\n",
            "INFO:tensorflow:Step 45900 per-step time 0.236s\n",
            "I0301 15:13:47.314426 140010801207104 model_lib_v2.py:705] Step 45900 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.053410042,\n",
            " 'Loss/localization_loss': 0.020604942,\n",
            " 'Loss/regularization_loss': 0.08127499,\n",
            " 'Loss/total_loss': 0.15528998,\n",
            " 'learning_rate': 0.0013740491}\n",
            "I0301 15:13:47.314730 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.053410042,\n",
            " 'Loss/localization_loss': 0.020604942,\n",
            " 'Loss/regularization_loss': 0.08127499,\n",
            " 'Loss/total_loss': 0.15528998,\n",
            " 'learning_rate': 0.0013740491}\n",
            "INFO:tensorflow:Step 46000 per-step time 0.237s\n",
            "I0301 15:14:10.970872 140010801207104 model_lib_v2.py:705] Step 46000 per-step time 0.237s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06789666,\n",
            " 'Loss/localization_loss': 0.022534719,\n",
            " 'Loss/regularization_loss': 0.08126638,\n",
            " 'Loss/total_loss': 0.17169777,\n",
            " 'learning_rate': 0.0013082051}\n",
            "I0301 15:14:10.971242 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.06789666,\n",
            " 'Loss/localization_loss': 0.022534719,\n",
            " 'Loss/regularization_loss': 0.08126638,\n",
            " 'Loss/total_loss': 0.17169777,\n",
            " 'learning_rate': 0.0013082051}\n",
            "INFO:tensorflow:Step 46100 per-step time 0.254s\n",
            "I0301 15:14:36.343900 140010801207104 model_lib_v2.py:705] Step 46100 per-step time 0.254s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.079575755,\n",
            " 'Loss/localization_loss': 0.04301167,\n",
            " 'Loss/regularization_loss': 0.08125811,\n",
            " 'Loss/total_loss': 0.20384553,\n",
            " 'learning_rate': 0.0012439513}\n",
            "I0301 15:14:36.344204 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.079575755,\n",
            " 'Loss/localization_loss': 0.04301167,\n",
            " 'Loss/regularization_loss': 0.08125811,\n",
            " 'Loss/total_loss': 0.20384553,\n",
            " 'learning_rate': 0.0012439513}\n",
            "INFO:tensorflow:Step 46200 per-step time 0.236s\n",
            "I0301 15:14:59.944517 140010801207104 model_lib_v2.py:705] Step 46200 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07283126,\n",
            " 'Loss/localization_loss': 0.018472338,\n",
            " 'Loss/regularization_loss': 0.08125027,\n",
            " 'Loss/total_loss': 0.17255387,\n",
            " 'learning_rate': 0.0011812877}\n",
            "I0301 15:14:59.944821 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.07283126,\n",
            " 'Loss/localization_loss': 0.018472338,\n",
            " 'Loss/regularization_loss': 0.08125027,\n",
            " 'Loss/total_loss': 0.17255387,\n",
            " 'learning_rate': 0.0011812877}\n",
            "INFO:tensorflow:Step 46300 per-step time 0.236s\n",
            "I0301 15:15:23.539530 140010801207104 model_lib_v2.py:705] Step 46300 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07422768,\n",
            " 'Loss/localization_loss': 0.040654156,\n",
            " 'Loss/regularization_loss': 0.081242815,\n",
            " 'Loss/total_loss': 0.19612466,\n",
            " 'learning_rate': 0.0011202192}\n",
            "I0301 15:15:23.539893 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.07422768,\n",
            " 'Loss/localization_loss': 0.040654156,\n",
            " 'Loss/regularization_loss': 0.081242815,\n",
            " 'Loss/total_loss': 0.19612466,\n",
            " 'learning_rate': 0.0011202192}\n",
            "INFO:tensorflow:Step 46400 per-step time 0.237s\n",
            "I0301 15:15:47.214328 140010801207104 model_lib_v2.py:705] Step 46400 per-step time 0.237s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.055457972,\n",
            " 'Loss/localization_loss': 0.02361524,\n",
            " 'Loss/regularization_loss': 0.081235796,\n",
            " 'Loss/total_loss': 0.16030902,\n",
            " 'learning_rate': 0.0010607505}\n",
            "I0301 15:15:47.214641 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.055457972,\n",
            " 'Loss/localization_loss': 0.02361524,\n",
            " 'Loss/regularization_loss': 0.081235796,\n",
            " 'Loss/total_loss': 0.16030902,\n",
            " 'learning_rate': 0.0010607505}\n",
            "INFO:tensorflow:Step 46500 per-step time 0.236s\n",
            "I0301 15:16:10.774826 140010801207104 model_lib_v2.py:705] Step 46500 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08054887,\n",
            " 'Loss/localization_loss': 0.0366049,\n",
            " 'Loss/regularization_loss': 0.08122913,\n",
            " 'Loss/total_loss': 0.19838288,\n",
            " 'learning_rate': 0.0010028839}\n",
            "I0301 15:16:10.775155 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.08054887,\n",
            " 'Loss/localization_loss': 0.0366049,\n",
            " 'Loss/regularization_loss': 0.08122913,\n",
            " 'Loss/total_loss': 0.19838288,\n",
            " 'learning_rate': 0.0010028839}\n",
            "INFO:tensorflow:Step 46600 per-step time 0.236s\n",
            "I0301 15:16:34.382383 140010801207104 model_lib_v2.py:705] Step 46600 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.058799118,\n",
            " 'Loss/localization_loss': 0.022853862,\n",
            " 'Loss/regularization_loss': 0.08122282,\n",
            " 'Loss/total_loss': 0.1628758,\n",
            " 'learning_rate': 0.0009466195}\n",
            "I0301 15:16:34.382791 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.058799118,\n",
            " 'Loss/localization_loss': 0.022853862,\n",
            " 'Loss/regularization_loss': 0.08122282,\n",
            " 'Loss/total_loss': 0.1628758,\n",
            " 'learning_rate': 0.0009466195}\n",
            "INFO:tensorflow:Step 46700 per-step time 0.237s\n",
            "I0301 15:16:58.051514 140010801207104 model_lib_v2.py:705] Step 46700 per-step time 0.237s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07519819,\n",
            " 'Loss/localization_loss': 0.021861637,\n",
            " 'Loss/regularization_loss': 0.08121686,\n",
            " 'Loss/total_loss': 0.17827669,\n",
            " 'learning_rate': 0.00089195726}\n",
            "I0301 15:16:58.051820 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.07519819,\n",
            " 'Loss/localization_loss': 0.021861637,\n",
            " 'Loss/regularization_loss': 0.08121686,\n",
            " 'Loss/total_loss': 0.17827669,\n",
            " 'learning_rate': 0.00089195726}\n",
            "INFO:tensorflow:Step 46800 per-step time 0.235s\n",
            "I0301 15:17:21.543103 140010801207104 model_lib_v2.py:705] Step 46800 per-step time 0.235s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.061221957,\n",
            " 'Loss/localization_loss': 0.028714638,\n",
            " 'Loss/regularization_loss': 0.08121125,\n",
            " 'Loss/total_loss': 0.17114785,\n",
            " 'learning_rate': 0.00083890435}\n",
            "I0301 15:17:21.543384 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.061221957,\n",
            " 'Loss/localization_loss': 0.028714638,\n",
            " 'Loss/regularization_loss': 0.08121125,\n",
            " 'Loss/total_loss': 0.17114785,\n",
            " 'learning_rate': 0.00083890435}\n",
            "INFO:tensorflow:Step 46900 per-step time 0.236s\n",
            "I0301 15:17:45.149219 140010801207104 model_lib_v2.py:705] Step 46900 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06587384,\n",
            " 'Loss/localization_loss': 0.013139664,\n",
            " 'Loss/regularization_loss': 0.08120598,\n",
            " 'Loss/total_loss': 0.16021949,\n",
            " 'learning_rate': 0.00078746316}\n",
            "I0301 15:17:45.149620 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.06587384,\n",
            " 'Loss/localization_loss': 0.013139664,\n",
            " 'Loss/regularization_loss': 0.08120598,\n",
            " 'Loss/total_loss': 0.16021949,\n",
            " 'learning_rate': 0.00078746316}\n",
            "INFO:tensorflow:Step 47000 per-step time 0.236s\n",
            "I0301 15:18:08.757406 140010801207104 model_lib_v2.py:705] Step 47000 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.068323106,\n",
            " 'Loss/localization_loss': 0.024417326,\n",
            " 'Loss/regularization_loss': 0.081201024,\n",
            " 'Loss/total_loss': 0.17394146,\n",
            " 'learning_rate': 0.0007376337}\n",
            "I0301 15:18:08.757747 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.068323106,\n",
            " 'Loss/localization_loss': 0.024417326,\n",
            " 'Loss/regularization_loss': 0.081201024,\n",
            " 'Loss/total_loss': 0.17394146,\n",
            " 'learning_rate': 0.0007376337}\n",
            "INFO:tensorflow:Step 47100 per-step time 0.252s\n",
            "I0301 15:18:33.961368 140010801207104 model_lib_v2.py:705] Step 47100 per-step time 0.252s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07525635,\n",
            " 'Loss/localization_loss': 0.016117446,\n",
            " 'Loss/regularization_loss': 0.081196405,\n",
            " 'Loss/total_loss': 0.1725702,\n",
            " 'learning_rate': 0.0006894159}\n",
            "I0301 15:18:33.961701 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.07525635,\n",
            " 'Loss/localization_loss': 0.016117446,\n",
            " 'Loss/regularization_loss': 0.081196405,\n",
            " 'Loss/total_loss': 0.1725702,\n",
            " 'learning_rate': 0.0006894159}\n",
            "INFO:tensorflow:Step 47200 per-step time 0.236s\n",
            "I0301 15:18:57.582478 140010801207104 model_lib_v2.py:705] Step 47200 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06303917,\n",
            " 'Loss/localization_loss': 0.031061307,\n",
            " 'Loss/regularization_loss': 0.08119208,\n",
            " 'Loss/total_loss': 0.17529255,\n",
            " 'learning_rate': 0.000642817}\n",
            "I0301 15:18:57.582786 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.06303917,\n",
            " 'Loss/localization_loss': 0.031061307,\n",
            " 'Loss/regularization_loss': 0.08119208,\n",
            " 'Loss/total_loss': 0.17529255,\n",
            " 'learning_rate': 0.000642817}\n",
            "INFO:tensorflow:Step 47300 per-step time 0.236s\n",
            "I0301 15:19:21.152711 140010801207104 model_lib_v2.py:705] Step 47300 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07884026,\n",
            " 'Loss/localization_loss': 0.028757824,\n",
            " 'Loss/regularization_loss': 0.08118803,\n",
            " 'Loss/total_loss': 0.18878612,\n",
            " 'learning_rate': 0.0005978322}\n",
            "I0301 15:19:21.153040 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.07884026,\n",
            " 'Loss/localization_loss': 0.028757824,\n",
            " 'Loss/regularization_loss': 0.08118803,\n",
            " 'Loss/total_loss': 0.18878612,\n",
            " 'learning_rate': 0.0005978322}\n",
            "INFO:tensorflow:Step 47400 per-step time 0.236s\n",
            "I0301 15:19:44.754892 140010801207104 model_lib_v2.py:705] Step 47400 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0743417,\n",
            " 'Loss/localization_loss': 0.02873624,\n",
            " 'Loss/regularization_loss': 0.08118429,\n",
            " 'Loss/total_loss': 0.18426223,\n",
            " 'learning_rate': 0.000554471}\n",
            "I0301 15:19:44.755351 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.0743417,\n",
            " 'Loss/localization_loss': 0.02873624,\n",
            " 'Loss/regularization_loss': 0.08118429,\n",
            " 'Loss/total_loss': 0.18426223,\n",
            " 'learning_rate': 0.000554471}\n",
            "INFO:tensorflow:Step 47500 per-step time 0.236s\n",
            "I0301 15:20:08.327789 140010801207104 model_lib_v2.py:705] Step 47500 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.102198854,\n",
            " 'Loss/localization_loss': 0.042573143,\n",
            " 'Loss/regularization_loss': 0.081180826,\n",
            " 'Loss/total_loss': 0.22595282,\n",
            " 'learning_rate': 0.0005127263}\n",
            "I0301 15:20:08.328136 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.102198854,\n",
            " 'Loss/localization_loss': 0.042573143,\n",
            " 'Loss/regularization_loss': 0.081180826,\n",
            " 'Loss/total_loss': 0.22595282,\n",
            " 'learning_rate': 0.0005127263}\n",
            "INFO:tensorflow:Step 47600 per-step time 0.236s\n",
            "I0301 15:20:31.980323 140010801207104 model_lib_v2.py:705] Step 47600 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07120473,\n",
            " 'Loss/localization_loss': 0.027516343,\n",
            " 'Loss/regularization_loss': 0.08117761,\n",
            " 'Loss/total_loss': 0.17989868,\n",
            " 'learning_rate': 0.00047260997}\n",
            "I0301 15:20:31.980703 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.07120473,\n",
            " 'Loss/localization_loss': 0.027516343,\n",
            " 'Loss/regularization_loss': 0.08117761,\n",
            " 'Loss/total_loss': 0.17989868,\n",
            " 'learning_rate': 0.00047260997}\n",
            "INFO:tensorflow:Step 47700 per-step time 0.236s\n",
            "I0301 15:20:55.576675 140010801207104 model_lib_v2.py:705] Step 47700 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.059231352,\n",
            " 'Loss/localization_loss': 0.016400779,\n",
            " 'Loss/regularization_loss': 0.08117465,\n",
            " 'Loss/total_loss': 0.15680678,\n",
            " 'learning_rate': 0.0004341173}\n",
            "I0301 15:20:55.577041 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.059231352,\n",
            " 'Loss/localization_loss': 0.016400779,\n",
            " 'Loss/regularization_loss': 0.08117465,\n",
            " 'Loss/total_loss': 0.15680678,\n",
            " 'learning_rate': 0.0004341173}\n",
            "INFO:tensorflow:Step 47800 per-step time 0.236s\n",
            "I0301 15:21:19.161971 140010801207104 model_lib_v2.py:705] Step 47800 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.062359523,\n",
            " 'Loss/localization_loss': 0.020800099,\n",
            " 'Loss/regularization_loss': 0.08117195,\n",
            " 'Loss/total_loss': 0.16433159,\n",
            " 'learning_rate': 0.00039724825}\n",
            "I0301 15:21:19.162286 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.062359523,\n",
            " 'Loss/localization_loss': 0.020800099,\n",
            " 'Loss/regularization_loss': 0.08117195,\n",
            " 'Loss/total_loss': 0.16433159,\n",
            " 'learning_rate': 0.00039724825}\n",
            "INFO:tensorflow:Step 47900 per-step time 0.236s\n",
            "I0301 15:21:42.816789 140010801207104 model_lib_v2.py:705] Step 47900 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.060892206,\n",
            " 'Loss/localization_loss': 0.022180682,\n",
            " 'Loss/regularization_loss': 0.08116948,\n",
            " 'Loss/total_loss': 0.16424236,\n",
            " 'learning_rate': 0.00036200762}\n",
            "I0301 15:21:42.817171 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.060892206,\n",
            " 'Loss/localization_loss': 0.022180682,\n",
            " 'Loss/regularization_loss': 0.08116948,\n",
            " 'Loss/total_loss': 0.16424236,\n",
            " 'learning_rate': 0.00036200762}\n",
            "INFO:tensorflow:Step 48000 per-step time 0.236s\n",
            "I0301 15:22:06.426862 140010801207104 model_lib_v2.py:705] Step 48000 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06505437,\n",
            " 'Loss/localization_loss': 0.03097436,\n",
            " 'Loss/regularization_loss': 0.08116722,\n",
            " 'Loss/total_loss': 0.17719595,\n",
            " 'learning_rate': 0.00032839776}\n",
            "I0301 15:22:06.427240 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.06505437,\n",
            " 'Loss/localization_loss': 0.03097436,\n",
            " 'Loss/regularization_loss': 0.08116722,\n",
            " 'Loss/total_loss': 0.17719595,\n",
            " 'learning_rate': 0.00032839776}\n",
            "INFO:tensorflow:Step 48100 per-step time 0.254s\n",
            "I0301 15:22:31.818806 140010801207104 model_lib_v2.py:705] Step 48100 per-step time 0.254s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07931855,\n",
            " 'Loss/localization_loss': 0.026533624,\n",
            " 'Loss/regularization_loss': 0.08116518,\n",
            " 'Loss/total_loss': 0.18701735,\n",
            " 'learning_rate': 0.00029641867}\n",
            "I0301 15:22:31.819126 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.07931855,\n",
            " 'Loss/localization_loss': 0.026533624,\n",
            " 'Loss/regularization_loss': 0.08116518,\n",
            " 'Loss/total_loss': 0.18701735,\n",
            " 'learning_rate': 0.00029641867}\n",
            "INFO:tensorflow:Step 48200 per-step time 0.236s\n",
            "I0301 15:22:55.465386 140010801207104 model_lib_v2.py:705] Step 48200 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07748582,\n",
            " 'Loss/localization_loss': 0.03405458,\n",
            " 'Loss/regularization_loss': 0.08116335,\n",
            " 'Loss/total_loss': 0.19270375,\n",
            " 'learning_rate': 0.00026607275}\n",
            "I0301 15:22:55.465739 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.07748582,\n",
            " 'Loss/localization_loss': 0.03405458,\n",
            " 'Loss/regularization_loss': 0.08116335,\n",
            " 'Loss/total_loss': 0.19270375,\n",
            " 'learning_rate': 0.00026607275}\n",
            "INFO:tensorflow:Step 48300 per-step time 0.235s\n",
            "I0301 15:23:18.998029 140010801207104 model_lib_v2.py:705] Step 48300 per-step time 0.235s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.074270755,\n",
            " 'Loss/localization_loss': 0.02416939,\n",
            " 'Loss/regularization_loss': 0.08116171,\n",
            " 'Loss/total_loss': 0.17960185,\n",
            " 'learning_rate': 0.00023735761}\n",
            "I0301 15:23:18.998366 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.074270755,\n",
            " 'Loss/localization_loss': 0.02416939,\n",
            " 'Loss/regularization_loss': 0.08116171,\n",
            " 'Loss/total_loss': 0.17960185,\n",
            " 'learning_rate': 0.00023735761}\n",
            "INFO:tensorflow:Step 48400 per-step time 0.235s\n",
            "I0301 15:23:42.507223 140010801207104 model_lib_v2.py:705] Step 48400 per-step time 0.235s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06520166,\n",
            " 'Loss/localization_loss': 0.035789482,\n",
            " 'Loss/regularization_loss': 0.08116022,\n",
            " 'Loss/total_loss': 0.18215136,\n",
            " 'learning_rate': 0.00021027803}\n",
            "I0301 15:23:42.507530 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.06520166,\n",
            " 'Loss/localization_loss': 0.035789482,\n",
            " 'Loss/regularization_loss': 0.08116022,\n",
            " 'Loss/total_loss': 0.18215136,\n",
            " 'learning_rate': 0.00021027803}\n",
            "INFO:tensorflow:Step 48500 per-step time 0.236s\n",
            "I0301 15:24:06.058846 140010801207104 model_lib_v2.py:705] Step 48500 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.077773236,\n",
            " 'Loss/localization_loss': 0.03243608,\n",
            " 'Loss/regularization_loss': 0.08115893,\n",
            " 'Loss/total_loss': 0.19136825,\n",
            " 'learning_rate': 0.000184834}\n",
            "I0301 15:24:06.059144 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.077773236,\n",
            " 'Loss/localization_loss': 0.03243608,\n",
            " 'Loss/regularization_loss': 0.08115893,\n",
            " 'Loss/total_loss': 0.19136825,\n",
            " 'learning_rate': 0.000184834}\n",
            "INFO:tensorflow:Step 48600 per-step time 0.237s\n",
            "I0301 15:24:29.731882 140010801207104 model_lib_v2.py:705] Step 48600 per-step time 0.237s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06992496,\n",
            " 'Loss/localization_loss': 0.016583584,\n",
            " 'Loss/regularization_loss': 0.08115778,\n",
            " 'Loss/total_loss': 0.16766632,\n",
            " 'learning_rate': 0.0001610279}\n",
            "I0301 15:24:29.732239 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.06992496,\n",
            " 'Loss/localization_loss': 0.016583584,\n",
            " 'Loss/regularization_loss': 0.08115778,\n",
            " 'Loss/total_loss': 0.16766632,\n",
            " 'learning_rate': 0.0001610279}\n",
            "INFO:tensorflow:Step 48700 per-step time 0.237s\n",
            "I0301 15:24:53.395277 140010801207104 model_lib_v2.py:705] Step 48700 per-step time 0.237s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06032069,\n",
            " 'Loss/localization_loss': 0.015318053,\n",
            " 'Loss/regularization_loss': 0.0811568,\n",
            " 'Loss/total_loss': 0.15679553,\n",
            " 'learning_rate': 0.00013885974}\n",
            "I0301 15:24:53.395587 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.06032069,\n",
            " 'Loss/localization_loss': 0.015318053,\n",
            " 'Loss/regularization_loss': 0.0811568,\n",
            " 'Loss/total_loss': 0.15679553,\n",
            " 'learning_rate': 0.00013885974}\n",
            "INFO:tensorflow:Step 48800 per-step time 0.236s\n",
            "I0301 15:25:17.000264 140010801207104 model_lib_v2.py:705] Step 48800 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.061944764,\n",
            " 'Loss/localization_loss': 0.013380536,\n",
            " 'Loss/regularization_loss': 0.08115595,\n",
            " 'Loss/total_loss': 0.15648125,\n",
            " 'learning_rate': 0.00011832714}\n",
            "I0301 15:25:17.000565 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.061944764,\n",
            " 'Loss/localization_loss': 0.013380536,\n",
            " 'Loss/regularization_loss': 0.08115595,\n",
            " 'Loss/total_loss': 0.15648125,\n",
            " 'learning_rate': 0.00011832714}\n",
            "INFO:tensorflow:Step 48900 per-step time 0.236s\n",
            "I0301 15:25:40.560368 140010801207104 model_lib_v2.py:705] Step 48900 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06473899,\n",
            " 'Loss/localization_loss': 0.02843717,\n",
            " 'Loss/regularization_loss': 0.08115523,\n",
            " 'Loss/total_loss': 0.1743314,\n",
            " 'learning_rate': 9.943485e-05}\n",
            "I0301 15:25:40.560741 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.06473899,\n",
            " 'Loss/localization_loss': 0.02843717,\n",
            " 'Loss/regularization_loss': 0.08115523,\n",
            " 'Loss/total_loss': 0.1743314,\n",
            " 'learning_rate': 9.943485e-05}\n",
            "INFO:tensorflow:Step 49000 per-step time 0.236s\n",
            "I0301 15:26:04.172869 140010801207104 model_lib_v2.py:705] Step 49000 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06926876,\n",
            " 'Loss/localization_loss': 0.032922726,\n",
            " 'Loss/regularization_loss': 0.08115463,\n",
            " 'Loss/total_loss': 0.18334612,\n",
            " 'learning_rate': 8.218288e-05}\n",
            "I0301 15:26:04.173182 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.06926876,\n",
            " 'Loss/localization_loss': 0.032922726,\n",
            " 'Loss/regularization_loss': 0.08115463,\n",
            " 'Loss/total_loss': 0.18334612,\n",
            " 'learning_rate': 8.218288e-05}\n",
            "INFO:tensorflow:Step 49100 per-step time 0.248s\n",
            "I0301 15:26:28.968439 140010801207104 model_lib_v2.py:705] Step 49100 per-step time 0.248s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06182071,\n",
            " 'Loss/localization_loss': 0.029514465,\n",
            " 'Loss/regularization_loss': 0.081154145,\n",
            " 'Loss/total_loss': 0.17248932,\n",
            " 'learning_rate': 6.6573615e-05}\n",
            "I0301 15:26:28.968765 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.06182071,\n",
            " 'Loss/localization_loss': 0.029514465,\n",
            " 'Loss/regularization_loss': 0.081154145,\n",
            " 'Loss/total_loss': 0.17248932,\n",
            " 'learning_rate': 6.6573615e-05}\n",
            "INFO:tensorflow:Step 49200 per-step time 0.236s\n",
            "I0301 15:26:52.526629 140010801207104 model_lib_v2.py:705] Step 49200 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06563363,\n",
            " 'Loss/localization_loss': 0.016949918,\n",
            " 'Loss/regularization_loss': 0.08115376,\n",
            " 'Loss/total_loss': 0.1637373,\n",
            " 'learning_rate': 5.2604675e-05}\n",
            "I0301 15:26:52.527000 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.06563363,\n",
            " 'Loss/localization_loss': 0.016949918,\n",
            " 'Loss/regularization_loss': 0.08115376,\n",
            " 'Loss/total_loss': 0.1637373,\n",
            " 'learning_rate': 5.2604675e-05}\n",
            "INFO:tensorflow:Step 49300 per-step time 0.237s\n",
            "I0301 15:27:16.246576 140010801207104 model_lib_v2.py:705] Step 49300 per-step time 0.237s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.079488404,\n",
            " 'Loss/localization_loss': 0.021853339,\n",
            " 'Loss/regularization_loss': 0.08115346,\n",
            " 'Loss/total_loss': 0.1824952,\n",
            " 'learning_rate': 4.0278435e-05}\n",
            "I0301 15:27:16.246877 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.079488404,\n",
            " 'Loss/localization_loss': 0.021853339,\n",
            " 'Loss/regularization_loss': 0.08115346,\n",
            " 'Loss/total_loss': 0.1824952,\n",
            " 'learning_rate': 4.0278435e-05}\n",
            "INFO:tensorflow:Step 49400 per-step time 0.236s\n",
            "I0301 15:27:39.821193 140010801207104 model_lib_v2.py:705] Step 49400 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06486338,\n",
            " 'Loss/localization_loss': 0.01327536,\n",
            " 'Loss/regularization_loss': 0.08115323,\n",
            " 'Loss/total_loss': 0.15929197,\n",
            " 'learning_rate': 2.9592513e-05}\n",
            "I0301 15:27:39.821491 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.06486338,\n",
            " 'Loss/localization_loss': 0.01327536,\n",
            " 'Loss/regularization_loss': 0.08115323,\n",
            " 'Loss/total_loss': 0.15929197,\n",
            " 'learning_rate': 2.9592513e-05}\n",
            "INFO:tensorflow:Step 49500 per-step time 0.235s\n",
            "I0301 15:28:03.349298 140010801207104 model_lib_v2.py:705] Step 49500 per-step time 0.235s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.060724743,\n",
            " 'Loss/localization_loss': 0.024986185,\n",
            " 'Loss/regularization_loss': 0.081153065,\n",
            " 'Loss/total_loss': 0.166864,\n",
            " 'learning_rate': 2.055168e-05}\n",
            "I0301 15:28:03.349668 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.060724743,\n",
            " 'Loss/localization_loss': 0.024986185,\n",
            " 'Loss/regularization_loss': 0.081153065,\n",
            " 'Loss/total_loss': 0.166864,\n",
            " 'learning_rate': 2.055168e-05}\n",
            "INFO:tensorflow:Step 49600 per-step time 0.236s\n",
            "I0301 15:28:26.945192 140010801207104 model_lib_v2.py:705] Step 49600 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.053682223,\n",
            " 'Loss/localization_loss': 0.024464726,\n",
            " 'Loss/regularization_loss': 0.08115297,\n",
            " 'Loss/total_loss': 0.15929991,\n",
            " 'learning_rate': 1.3153553e-05}\n",
            "I0301 15:28:26.945491 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.053682223,\n",
            " 'Loss/localization_loss': 0.024464726,\n",
            " 'Loss/regularization_loss': 0.08115297,\n",
            " 'Loss/total_loss': 0.15929991,\n",
            " 'learning_rate': 1.3153553e-05}\n",
            "INFO:tensorflow:Step 49700 per-step time 0.236s\n",
            "I0301 15:28:50.505468 140010801207104 model_lib_v2.py:705] Step 49700 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.060977597,\n",
            " 'Loss/localization_loss': 0.024077814,\n",
            " 'Loss/regularization_loss': 0.0811529,\n",
            " 'Loss/total_loss': 0.16620831,\n",
            " 'learning_rate': 7.398128e-06}\n",
            "I0301 15:28:50.505768 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.060977597,\n",
            " 'Loss/localization_loss': 0.024077814,\n",
            " 'Loss/regularization_loss': 0.0811529,\n",
            " 'Loss/total_loss': 0.16620831,\n",
            " 'learning_rate': 7.398128e-06}\n",
            "INFO:tensorflow:Step 49800 per-step time 0.236s\n",
            "I0301 15:29:14.113433 140010801207104 model_lib_v2.py:705] Step 49800 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05308892,\n",
            " 'Loss/localization_loss': 0.0146359205,\n",
            " 'Loss/regularization_loss': 0.08115287,\n",
            " 'Loss/total_loss': 0.14887771,\n",
            " 'learning_rate': 3.2877922e-06}\n",
            "I0301 15:29:14.113785 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.05308892,\n",
            " 'Loss/localization_loss': 0.0146359205,\n",
            " 'Loss/regularization_loss': 0.08115287,\n",
            " 'Loss/total_loss': 0.14887771,\n",
            " 'learning_rate': 3.2877922e-06}\n",
            "INFO:tensorflow:Step 49900 per-step time 0.236s\n",
            "I0301 15:29:37.710342 140010801207104 model_lib_v2.py:705] Step 49900 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06516458,\n",
            " 'Loss/localization_loss': 0.031633705,\n",
            " 'Loss/regularization_loss': 0.08115287,\n",
            " 'Loss/total_loss': 0.17795116,\n",
            " 'learning_rate': 8.2254405e-07}\n",
            "I0301 15:29:37.710709 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.06516458,\n",
            " 'Loss/localization_loss': 0.031633705,\n",
            " 'Loss/regularization_loss': 0.08115287,\n",
            " 'Loss/total_loss': 0.17795116,\n",
            " 'learning_rate': 8.2254405e-07}\n",
            "INFO:tensorflow:Step 50000 per-step time 0.236s\n",
            "I0301 15:30:01.296404 140010801207104 model_lib_v2.py:705] Step 50000 per-step time 0.236s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05425082,\n",
            " 'Loss/localization_loss': 0.02809108,\n",
            " 'Loss/regularization_loss': 0.08115287,\n",
            " 'Loss/total_loss': 0.16349477,\n",
            " 'learning_rate': 0.0}\n",
            "I0301 15:30:01.296697 140010801207104 model_lib_v2.py:708] {'Loss/classification_loss': 0.05425082,\n",
            " 'Loss/localization_loss': 0.02809108,\n",
            " 'Loss/regularization_loss': 0.08115287,\n",
            " 'Loss/total_loss': 0.16349477,\n",
            " 'learning_rate': 0.0}\n"
          ]
        }
      ],
      "source": [
        "# Run the command below from the content/models/research/object_detection directory\n",
        "\n",
        "\"\"\"\n",
        "PIPELINE_CONFIG_PATH=path/to/pipeline.config\n",
        "MODEL_DIR=path to training checkpoints directory\n",
        "NUM_TRAIN_STEPS=50000\n",
        "SAMPLE_1_OF_N_EVAL_EXAMPLES=1\n",
        "\n",
        "python model_main_tf2.py -- \\\n",
        "--model_dir=$MODEL_DIR --num_train_steps=$NUM_TRAIN_STEPS \\\n",
        "--sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \\\n",
        "--pipeline_config_path=$PIPELINE_CONFIG_PATH \\\n",
        "--alsologtostderr\n",
        "\"\"\"\n",
        "\n",
        "!python model_main_tf2.py --pipeline_config_path=/content/gdrive/MyDrive/customTF2/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --model_dir=/content/gdrive/MyDrive/customTF2/training  --alsologtostderr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c074OXLcnczI",
        "outputId": "2b7b199e-9405-4d81-bcfe-c7380944e6cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-03-01 15:37:06.050709: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-01 15:37:06.050831: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-01 15:37:06.050856: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0301 15:37:09.977833 139947141379904 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I0301 15:37:09.978085 139947141379904 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0301 15:37:09.978166 139947141379904 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0301 15:37:09.978244 139947141379904 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0301 15:37:09.978360 139947141379904 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "2023-03-01 15:37:11.136806: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/gdrive/MyDrive/customTF2/data/test.record']\n",
            "I0301 15:37:11.247937 139947141379904 dataset_builder.py:162] Reading unweighted datasets: ['/content/gdrive/MyDrive/customTF2/data/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/gdrive/MyDrive/customTF2/data/test.record']\n",
            "I0301 15:37:11.249476 139947141379904 dataset_builder.py:79] Reading record datasets for input file: ['/content/gdrive/MyDrive/customTF2/data/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0301 15:37:11.249668 139947141379904 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0301 15:37:11.249753 139947141379904 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0301 15:37:11.254667 139947141379904 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0301 15:37:11.278981 139947141379904 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "W0301 15:37:12.159077 139947141379904 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0301 15:37:16.260099 139947141379904 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0301 15:37:17.076777 139947141379904 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/gdrive/MyDrive/customTF2/training/\n",
            "I0301 15:37:19.231070 139947141379904 checkpoint_utils.py:140] Waiting for new checkpoint at /content/gdrive/MyDrive/customTF2/training/\n",
            "INFO:tensorflow:Found new checkpoint at /content/gdrive/MyDrive/customTF2/training/ckpt-51\n",
            "I0301 15:37:19.233788 139947141379904 checkpoint_utils.py:149] Found new checkpoint at /content/gdrive/MyDrive/customTF2/training/ckpt-51\n",
            "/usr/local/lib/python3.8/dist-packages/keras/backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0301 15:38:12.320734 139947141379904 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0301 15:38:12.348725 139947141379904 model_lib_v2.py:966] Finished eval step 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0301 15:38:12.479513 139947141379904 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0301 15:38:28.819304 139947141379904 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I0301 15:38:42.988964 139947141379904 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Finished eval step 300\n",
            "I0301 15:38:57.387633 139947141379904 model_lib_v2.py:966] Finished eval step 300\n",
            "INFO:tensorflow:Finished eval step 400\n",
            "I0301 15:39:13.551040 139947141379904 model_lib_v2.py:966] Finished eval step 400\n",
            "INFO:tensorflow:Performing evaluation on 442 images.\n",
            "I0301 15:39:41.502556 139947141379904 coco_evaluation.py:293] Performing evaluation on 442 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0301 15:39:41.506584 139947141379904 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I0301 15:39:41.528959 139947141379904 coco_tools.py:138] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.50s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.427\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.695\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.450\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.289\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.511\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.606\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.514\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.562\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.563\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.459\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.631\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\n",
            "INFO:tensorflow:Eval metrics at step 50000\n",
            "I0301 15:39:47.261222 139947141379904 model_lib_v2.py:1015] Eval metrics at step 50000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.426841\n",
            "I0301 15:39:47.267993 139947141379904 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.426841\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.694792\n",
            "I0301 15:39:47.269726 139947141379904 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.694792\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.450054\n",
            "I0301 15:39:47.271208 139947141379904 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.450054\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.288539\n",
            "I0301 15:39:47.272672 139947141379904 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.288539\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.511136\n",
            "I0301 15:39:47.274117 139947141379904 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.511136\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.606076\n",
            "I0301 15:39:47.275541 139947141379904 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.606076\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.513862\n",
            "I0301 15:39:47.277023 139947141379904 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.513862\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.562182\n",
            "I0301 15:39:47.278450 139947141379904 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.562182\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.562689\n",
            "I0301 15:39:47.279826 139947141379904 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.562689\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.458525\n",
            "I0301 15:39:47.281145 139947141379904 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.458525\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.631385\n",
            "I0301 15:39:47.282485 139947141379904 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.631385\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.655833\n",
            "I0301 15:39:47.284034 139947141379904 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.655833\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.187686\n",
            "I0301 15:39:47.285078 139947141379904 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.187686\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.427319\n",
            "I0301 15:39:47.286153 139947141379904 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.427319\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.081153\n",
            "I0301 15:39:47.287512 139947141379904 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.081153\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.696158\n",
            "I0301 15:39:47.288531 139947141379904 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.696158\n",
            "INFO:tensorflow:Exiting evaluation at step 50000\n",
            "I0301 15:39:47.660069 139947141379904 model_lib_v2.py:1168] Exiting evaluation at step 50000\n"
          ]
        }
      ],
      "source": [
        "!python model_main_tf2.py --pipeline_config_path=/content/gdrive/MyDrive/customTF2/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --model_dir=/content/gdrive/MyDrive/customTF2/training --alsologtostderr --checkpoint_dir=/content/gdrive/MyDrive/customTF2/training/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeX1WtoEr8ZY",
        "outputId": "f2f15be4-b270-4ad5-ab1f-4eb9c30a4f8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-03-02 16:17:31.639778: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-02 16:17:31.639878: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-02 16:17:31.639897: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-02 16:17:37.817007: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "W0302 16:17:41.897309 140104615573312 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0302 16:17:42.247100 140104615573312 deprecation.py:623] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f6c200f7580>, because it is not built.\n",
            "W0302 16:18:57.827254 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f6c200f7580>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f6ba8442460>, because it is not built.\n",
            "W0302 16:18:58.212092 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f6ba8442460>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6ba81786a0>, because it is not built.\n",
            "W0302 16:18:58.212344 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6ba81786a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba8178910>, because it is not built.\n",
            "W0302 16:18:58.212472 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba8178910>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f6ba8178a30>, because it is not built.\n",
            "W0302 16:18:58.212578 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f6ba8178a30>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6ba83b81c0>, because it is not built.\n",
            "W0302 16:18:58.212678 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6ba83b81c0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6baa0d6940>, because it is not built.\n",
            "W0302 16:18:58.212773 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6baa0d6940>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f6baa0e5a90>, because it is not built.\n",
            "W0302 16:18:58.212857 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f6baa0e5a90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6baa0e5c10>, because it is not built.\n",
            "W0302 16:18:58.212947 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6baa0e5c10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6baa0e5af0>, because it is not built.\n",
            "W0302 16:18:58.213055 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6baa0e5af0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f6b98f19fd0>, because it is not built.\n",
            "W0302 16:18:58.213148 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f6b98f19fd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6ba83f1910>, because it is not built.\n",
            "W0302 16:18:58.213254 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6ba83f1910>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba83f1be0>, because it is not built.\n",
            "W0302 16:18:58.213346 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba83f1be0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6ba81a6cd0>, because it is not built.\n",
            "W0302 16:18:58.213436 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6ba81a6cd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba83f3fa0>, because it is not built.\n",
            "W0302 16:18:58.213526 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba83f3fa0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6ba8222b20>, because it is not built.\n",
            "W0302 16:18:58.213613 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6ba8222b20>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba829d3a0>, because it is not built.\n",
            "W0302 16:18:58.213693 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba829d3a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6b98dc4820>, because it is not built.\n",
            "W0302 16:18:58.213777 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6b98dc4820>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6b98dc48e0>, because it is not built.\n",
            "W0302 16:18:58.213863 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6b98dc48e0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6b98dc4d00>, because it is not built.\n",
            "W0302 16:18:58.213949 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6b98dc4d00>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6b98dc4c10>, because it is not built.\n",
            "W0302 16:18:58.214053 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6b98dc4c10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6ba84b2070>, because it is not built.\n",
            "W0302 16:18:58.214141 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6ba84b2070>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba83d75e0>, because it is not built.\n",
            "W0302 16:18:58.214240 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba83d75e0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6b98e77430>, because it is not built.\n",
            "W0302 16:18:58.214338 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6b98e77430>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6b98e77550>, because it is not built.\n",
            "W0302 16:18:58.214429 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6b98e77550>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6b98e77a00>, because it is not built.\n",
            "W0302 16:18:58.214514 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6b98e77a00>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6b98e77d90>, because it is not built.\n",
            "W0302 16:18:58.214592 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6b98e77d90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6b98e70190>, because it is not built.\n",
            "W0302 16:18:58.214677 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6b98e70190>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6b98e70250>, because it is not built.\n",
            "W0302 16:18:58.214767 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6b98e70250>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6b98e70f40>, because it is not built.\n",
            "W0302 16:18:58.214857 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6b98e70f40>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6b98ddc910>, because it is not built.\n",
            "W0302 16:18:58.214944 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6b98ddc910>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6b98ddcca0>, because it is not built.\n",
            "W0302 16:18:58.215048 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6b98ddcca0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6b98ddce80>, because it is not built.\n",
            "W0302 16:18:58.215138 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6b98ddce80>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6b98ddd4c0>, because it is not built.\n",
            "W0302 16:18:58.215248 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6b98ddd4c0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6b98dddb20>, because it is not built.\n",
            "W0302 16:18:58.215337 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6b98dddb20>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6b98ddd0d0>, because it is not built.\n",
            "W0302 16:18:58.215418 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6b98ddd0d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba8288af0>, because it is not built.\n",
            "W0302 16:18:58.215506 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba8288af0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6ba8041e80>, because it is not built.\n",
            "W0302 16:18:58.215593 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6ba8041e80>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba818d040>, because it is not built.\n",
            "W0302 16:18:58.215681 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba818d040>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6baa110190>, because it is not built.\n",
            "W0302 16:18:58.215776 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6baa110190>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba846f4f0>, because it is not built.\n",
            "W0302 16:18:58.215863 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba846f4f0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6ba846f5b0>, because it is not built.\n",
            "W0302 16:18:58.215951 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6ba846f5b0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba84af670>, because it is not built.\n",
            "W0302 16:18:58.216051 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba84af670>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6ba9fcb370>, because it is not built.\n",
            "W0302 16:18:58.224405 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6ba9fcb370>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba9fcb100>, because it is not built.\n",
            "W0302 16:18:58.224544 140104615573312 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f6ba9fcb100>, because it is not built.\n",
            "W0302 16:19:21.016926 140104615573312 save.py:271] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 173). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/customTF2/data/inference_graph/saved_model/assets\n",
            "I0302 16:19:28.040602 140104615573312 builder_impl.py:797] Assets written to: /content/gdrive/MyDrive/customTF2/data/inference_graph/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to /content/gdrive/MyDrive/customTF2/data/inference_graph/pipeline.config\n",
            "I0302 16:19:29.861947 140104615573312 config_util.py:253] Writing pipeline config file to /content/gdrive/MyDrive/customTF2/data/inference_graph/pipeline.config\n"
          ]
        }
      ],
      "source": [
        "!python exporter_main_v2.py --trained_checkpoint_dir=/content/gdrive/MyDrive/customTF2/training --pipeline_config_path=/content/gdrive/MyDrive/customTF2/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --output_directory /content/gdrive/MyDrive/customTF2/data/inference_graph"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}